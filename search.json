[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Web Scraping to compare movies and actors",
    "section": "",
    "text": "To compare the actors starred in our favorite movies, we must first scrape the TMDB website to collect information on the corresponding movies’ actors. To begin scraping, we must first import all libraries we’ll be using.\nfrom scrapy.spiders import Spider\nfrom scrapy.http import Request\nfrom scrapy.linkextractors import LinkExtractor\nimport random\nimport scrapy\nimport pandas as pd\nThe first few libraries will help us crawl through the sites themselves and navigate from one page to the next to extract all the actors we are looking for. The last library is used to create a pandas dataframe which we’ll see at the end."
  },
  {
    "objectID": "index.html#import-libraries",
    "href": "index.html#import-libraries",
    "title": "Web Scraping to compare movies and actors",
    "section": "",
    "text": "To compare the actors starred in our favorite movies, we must first scrape the TMDB website to collect information on the corresponding movies’ actors. To begin scraping, we must first import all libraries we’ll be using.\nfrom scrapy.spiders import Spider\nfrom scrapy.http import Request\nfrom scrapy.linkextractors import LinkExtractor\nimport random\nimport scrapy\nimport pandas as pd\nThe first few libraries will help us crawl through the sites themselves and navigate from one page to the next to extract all the actors we are looking for. The last library is used to create a pandas dataframe which we’ll see at the end."
  },
  {
    "objectID": "index.html#parse-through-the-website",
    "href": "index.html#parse-through-the-website",
    "title": "Web Scraping to compare movies and actors",
    "section": "Parse through the website",
    "text": "Parse through the website\nThe code below provides the url for where we start scraping. Using the f strings allows us to implement {subdir} as a parameter when we initialize our scraper.\nclass TmdbSpider(scrapy.Spider):\n    name = 'tmdb_spider'\n\n    def __init__(self, subdir=\"\", *args, **kwargs):\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"] \n\n\n\nThree parsing methods:\n\nMethod 1:\nStarting at the movie page, we’ll navigate to the Full Cast & Crew page by hardcoding the cast page of the movie Through the yield Request, we’re calling the next parsing method to navigate through the actual list of actors.\n    def parse(self, response):\n        cast_url = response.url + '/cast' \n        yield scrapy.Request(cast_url, callback=self.parse_full_credits)\n\n\nMethod 2:\nThen we’ll use the following method to join each actor in a list and navigate to their pages We first use respose.css() in combination with the .getall() method to sift through the column of actors themselves in the cast column and ignore the crew column. The for loop will then navigate and join the individual actor’s links so that that the yield request can call the next parsing method after crawling through these actors’ links.\n    def parse_full_credits(self, response):\n        cast_links = response.css('ol.people.credits li a::attr(href)').getall()\n        \n        for actor in cast_links:\n            cast_url = response.urljoin(actor) \n            yield scrapy.Request(url = cast_url, callback = self.parse_actor_page)\n\n\nMethod 3:\nNow starting at an actor’s page from the list, we can navigate the actor’s name As before, we use response.css() with the .get() method this time to find all the actor’s names, and now we can look each indivdual’s roles they’ve been casted for. Here we want to create an empty set because we started with a list of the actor’s names, but we want to prevent any of their roles being listed more than once. Because set’s can only contain one element once, this prevents any duplicates. Then we can proceed to adding the name of each movie/TV show the actors were casted in from the list of roles into the set.\n    def parse_actor_page(self, response):\n       \n        actor_name = response.css('h2.title a::text').get()\n        roles = response.css('td.role')\n\n        cleaned_roles = set()\n\n        for role in roles:\n            movie_or_TV_name = role.css('a.tooltip bdi::text').get() \n            \n            if movie_or_TV_name not in cleaned_roles:\n                yield{\n                \"actor\" : actor_name, \n                \"movie_or_TV_name\" : movie_or_TV_name\n                }"
  },
  {
    "objectID": "index.html#now-that-we-have-found-our-results-we-can-create-out-visual-table-using-a-pandas-dataframe",
    "href": "index.html#now-that-we-have-found-our-results-we-can-create-out-visual-table-using-a-pandas-dataframe",
    "title": "Web Scraping to compare movies and actors",
    "section": "Now that we have found our results, we can create out visual table using a pandas dataframe",
    "text": "Now that we have found our results, we can create out visual table using a pandas dataframe\nLet’s compare two movies Sarah Burnett chose her favorite film as Harry Potter and the Philosopher’s Stone while Reina Schmoock Chose Interstellar. We want to compare our favorite films to see what movies/TV shows the actors are casted in are shared between the two sets of actors.\n\nHere are the two csv files of Sarah’s favorite film and Reina’s favorite film\nresults = pd.read_csv(\"results.csv\")\nmy_results = pd.read_csv(\"my_results.csv\")\nFirst, we have the dataframe of actors from Harry Potter and their other roles\n\nNext, we have the dataframe of actors from Interstellar and their other roles\n\n\n\nTo compare the titles of movies/TV shows that appear in both dataframes, we merge the two dataframes together to create one new dataframe called share_title!\n# These are titles that are shared between actors of HP and Interstellar\nshare_title = pd.merge(results, my_results, on = \"movie_or_TV_name\")\nshare_title.columns = pd.Index(['HP', 'Title', 'Actor'])\nshare_title = share_title[['Title', 'Actor']]\nshare_title\nLet’s look at how this table looks below:\n\n\n\nBecause there’s so many rows between so many actors, let’s look at the first 20 results:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Web Scraping to compare movies and actors",
    "section": "",
    "text": "To compare the actors starred in our favorite movies, we must first scrape the TMDB website to collect information on the corresponding movies’ actors. To begin scraping, we must first import all libraries we’ll be using.\nfrom scrapy.spiders import Spider\nfrom scrapy.http import Request\nfrom scrapy.linkextractors import LinkExtractor\nimport random\nimport scrapy\nimport pandas as pd\nThe first few libraries will help us crawl through the sites themselves and navigate from one page to the next to extract all the actors we are looking for. The last library is used to create a pandas dataframe which we’ll see at the end."
  },
  {
    "objectID": "posts/post-with-code/index.html#import-libraries",
    "href": "posts/post-with-code/index.html#import-libraries",
    "title": "Web Scraping to compare movies and actors",
    "section": "",
    "text": "To compare the actors starred in our favorite movies, we must first scrape the TMDB website to collect information on the corresponding movies’ actors. To begin scraping, we must first import all libraries we’ll be using.\nfrom scrapy.spiders import Spider\nfrom scrapy.http import Request\nfrom scrapy.linkextractors import LinkExtractor\nimport random\nimport scrapy\nimport pandas as pd\nThe first few libraries will help us crawl through the sites themselves and navigate from one page to the next to extract all the actors we are looking for. The last library is used to create a pandas dataframe which we’ll see at the end."
  },
  {
    "objectID": "posts/post-with-code/index.html#parse-through-the-website",
    "href": "posts/post-with-code/index.html#parse-through-the-website",
    "title": "Web Scraping to compare movies and actors",
    "section": "Parse through the website",
    "text": "Parse through the website\nThe code below provides the url for where we start scraping. Using the f strings allows us to implement {subdir} as a parameter when we initialize our scraper.\nclass TmdbSpider(scrapy.Spider):\n    name = 'tmdb_spider'\n\n    def __init__(self, subdir=\"\", *args, **kwargs):\n        self.start_urls = [f\"https://www.themoviedb.org/movie/{subdir}/\"] \n\n\n\nThree parsing methods:\n\nMethod 1:\nStarting at the movie page, we’ll navigate to the Full Cast & Crew page by hardcoding the cast page of the movie Through the yield Request, we’re calling the next parsing method to navigate through the actual list of actors.\n    def parse(self, response):\n        cast_url = response.url + '/cast' \n        yield scrapy.Request(cast_url, callback=self.parse_full_credits)\n\n\nMethod 2:\nThen we’ll use the following method to join each actor in a list and navigate to their pages We first use respose.css() in combination with the .getall() method to sift through the column of actors themselves in the cast column and ignore the crew column. The for loop will then navigate and join the individual actor’s links so that that the yield request can call the next parsing method after crawling through these actors’ links.\n    def parse_full_credits(self, response):\n        cast_links = response.css('ol.people.credits li a::attr(href)').getall()\n        \n        for actor in cast_links:\n            cast_url = response.urljoin(actor) \n            yield scrapy.Request(url = cast_url, callback = self.parse_actor_page)\n\n\nMethod 3:\nNow starting at an actor’s page from the list, we can navigate the actor’s name As before, we use response.css() with the .get() method this time to find all the actor’s names, and now we can look each indivdual’s roles they’ve been casted for. Here we want to create an empty set because we started with a list of the actor’s names, but we want to prevent any of their roles being listed more than once. Because set’s can only contain one element once, this prevents any duplicates. Then we can proceed to adding the name of each movie/TV show the actors were casted in from the list of roles into the set.\n    def parse_actor_page(self, response):\n       \n        actor_name = response.css('h2.title a::text').get()\n        roles = response.css('td.role')\n\n        cleaned_roles = set()\n\n        for role in roles:\n            movie_or_TV_name = role.css('a.tooltip bdi::text').get() \n            \n            if movie_or_TV_name not in cleaned_roles:\n                yield{\n                \"actor\" : actor_name, \n                \"movie_or_TV_name\" : movie_or_TV_name\n                }"
  },
  {
    "objectID": "posts/post-with-code/index.html#now-that-we-have-found-our-results-we-can-create-out-visual-table-using-a-pandas-dataframe",
    "href": "posts/post-with-code/index.html#now-that-we-have-found-our-results-we-can-create-out-visual-table-using-a-pandas-dataframe",
    "title": "Web Scraping to compare movies and actors",
    "section": "Now that we have found our results, we can create out visual table using a pandas dataframe",
    "text": "Now that we have found our results, we can create out visual table using a pandas dataframe\nLet’s compare two movies Sarah Burnett chose her favorite film as Harry Potter and the Philosopher’s Stone while Reina Schmoock Chose Interstellar. We want to compare our favorite films to see what movies/TV shows the actors are casted in are shared between the two sets of actors.\n\nHere are the two csv files of Sarah’s favorite film and Reina’s favorite film\nresults = pd.read_csv(\"results.csv\")\nmy_results = pd.read_csv(\"my_results.csv\")\nFirst, we have the dataframe of actors from Harry Potter and their other roles\n\nNext, we have the dataframe of actors from Interstellar and their other roles\n\n\n\nTo compare the titles of movies/TV shows that appear in both dataframes, we merge the two dataframes together to create one new dataframe called share_title!\n# These are titles that are shared between actors of HP and Interstellar\nshare_title = pd.merge(results, my_results, on = \"movie_or_TV_name\")\nshare_title.columns = pd.Index(['HP', 'Title', 'Actor'])\nshare_title = share_title[['Title', 'Actor']]\nshare_title\nLet’s look at how this table looks below:\n\n\n\nBecause there’s so many rows between so many actors, let’s look at the first 20 results:"
  }
]